{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xGLxiF7lrns"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data perprocessing expalined in Ensemble1.ipynb file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeghhyxlGnxq"
      },
      "outputs": [],
      "source": [
        "policy_df =pd.read_csv('policies.csv')\n",
        "driver_df =pd.read_csv('drivers.csv')\n",
        "vehicle_df =pd.read_csv('vehicles.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91hvdqbzuEc8"
      },
      "outputs": [],
      "source": [
        "policy_df = policy_df[policy_df['split'] == \"Train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF6Zls6Euj3F",
        "outputId": "3701cbfb-f7e4-4acf-b3e2-229d6298e284"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['Unnamed: 0','Agent_cd','zip','state_id', 'county_name','CAT_zone', 'split'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbWN1mrrujo_",
        "outputId": "99e99eb1-b6fb-4597-f68e-ae440800ccaa"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['num_loaned_veh', 'num_owned_veh', 'num_leased_veh'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEXXbTnDujiZ"
      },
      "outputs": [],
      "source": [
        "policy_df['Quote_dt'] = pd.to_datetime(policy_df['Quote_dt'])\n",
        "policy_df['Quote_month'] = policy_df['Quote_dt'].dt.month\n",
        "policy_df['Quote_quarter'] = policy_df['Quote_dt'].dt.quarter\n",
        "policy_df['Quote_year'] = policy_df['Quote_dt'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxMwDnEujcL",
        "outputId": "d1d534b7-015c-4dbf-adef-c0757a11ba4c"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['Quote_dt'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVOWOXrew9V7",
        "outputId": "7d550dfa-462e-4602-98d3-44a62106ee6c"
      },
      "outputs": [],
      "source": [
        "policy_df['quote'] = policy_df['quoted_amt'].str.replace(',','')\n",
        "policy_df['quote'] = policy_df['quote'].str.replace('$','')\n",
        "policy_df['quote'] = pd.to_numeric(policy_df['quote'], errors='coerce')\n",
        "policy_df['quote'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQIXrMcLw9Nc",
        "outputId": "117f85c3-d3d9-4ce5-8f6c-31044aabfbad"
      },
      "outputs": [],
      "source": [
        "policy_df['quote'].describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "changequote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N4n2Mhww9I6"
      },
      "outputs": [],
      "source": [
        "policy_df['quote_cats'] = pd.qcut(policy_df['quote'], q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y0FZ30z1Cf1",
        "outputId": "89270f1e-bb4d-4fa9-b3f3-b872248e4bdc"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['quote'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed_dmm7tzoGv",
        "outputId": "a6da8699-cbdd-4400-b968-2738d25a1705"
      },
      "outputs": [],
      "source": [
        "policy_df['primary_parking'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk0ML_K8zoCE",
        "outputId": "abd382b3-b974-4ef9-fad4-1b8012cebfa6"
      },
      "outputs": [],
      "source": [
        "policy_df['Cov_package_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDgdb1h3w8_R",
        "outputId": "c7a72bff-e545-430e-d4d6-a09ffb3ea675"
      },
      "outputs": [],
      "source": [
        "policy_df['Prior_carrier_grp'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbrM6WPcw863"
      },
      "outputs": [],
      "source": [
        "policy_df['credit_score'] = pd.to_numeric(policy_df['credit_score'])\n",
        "score_ranges = [0, 579, 669, 739, 799, 850]\n",
        "score_categories = ['Very Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
        "policy_df['score_category'] = pd.cut(policy_df['credit_score'],\n",
        "                                     bins=score_ranges, labels=score_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "V5fjfK7G1Nd1",
        "outputId": "3789fcb8-35a0-4ec5-dcc1-d37d7cf2594e"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9DM7vygzK3p"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['quoted_amt', 'credit_score' ], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "oKSE5RmdzKy5",
        "outputId": "cb932f5b-60b1-4ab6-8863-0a45134061e7"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6QsNonbzKpC"
      },
      "outputs": [],
      "source": [
        "policy_df = pd.get_dummies(policy_df, columns = ['discount','Home_policy_ind','Prior_carrier_grp','Cov_package_type',\n",
        "                                                 'Quote_month', 'quote_cats', 'Quote_quarter', 'Quote_year', 'score_category',\n",
        "                                                 'primary_parking'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UQ0jXhkWzKi6",
        "outputId": "a8cc1762-83d6-441d-bcba-83cb1bc85692"
      },
      "outputs": [],
      "source": [
        "#policy_df..columns()\n",
        "policy_df.head()\n",
        "#policy_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkkDagxezKd_",
        "outputId": "3ab0a6c4-8b02-419e-e0ea-c9ceee419642"
      },
      "outputs": [],
      "source": [
        "np.shape(policy_df)\n",
        "#Cleaned Policy Datset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drivers Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KPSlGn7QfyhG",
        "outputId": "2cb154a0-0e51-457e-b816-a409ec568930"
      },
      "outputs": [],
      "source": [
        "driver_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_0xf2oF6Gnq6",
        "outputId": "85b774ec-bede-491c-e2b6-87c8977c5f28"
      },
      "outputs": [],
      "source": [
        "driver_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6o-ZbgW3-RO",
        "outputId": "21f2fd44-b9d0-43f8-a2b9-3c013bf57321"
      },
      "outputs": [],
      "source": [
        "driver_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnMQ22uiiuvR",
        "outputId": "cf9577fa-c579-4407-a226-98ed80334e64"
      },
      "outputs": [],
      "source": [
        "driver_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ob2zQu-Tlcuc",
        "outputId": "84cf23c2-6c64-4818-f5f3-e0d6715dc1e5"
      },
      "outputs": [],
      "source": [
        "driver_df[driver_df['age']>100].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMsd7VYAlcqI"
      },
      "outputs": [],
      "source": [
        "driver_df = driver_df.drop(driver_df[driver_df['age'] > 100].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXk1MNT3ngUf"
      },
      "outputs": [],
      "source": [
        "driver_df['Age_group'] = pd.cut(driver_df['age'], \n",
        "                         [0, 19, 34, 44, 64, 84], \n",
        "                         labels=['Teenagers', 'Young adults', 'Middle-aged adults','Old Adults', 'Older adults'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhpjL1ptGSoA"
      },
      "outputs": [],
      "source": [
        "driver_df.drop(['age'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "WRjMjV-BngHf",
        "outputId": "900b5073-525e-4a5b-e234-558d4846d405"
      },
      "outputs": [],
      "source": [
        "driver_df = pd.get_dummies(driver_df, columns = ['gender', 'living_status', 'Age_group' ,'high_education_ind'])\n",
        "driver_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiAA_A2fqobQ"
      },
      "outputs": [],
      "source": [
        "bool_cols1 = [col for col in driver_df \n",
        "              if np.isin(driver_df[col].dropna().unique(), [0, 1]).all()]\n",
        "bool_cols1\n",
        "safty_rating_mean = driver_df['safty_rating']\n",
        "if safty_rating_mean.isnull().values.any():\n",
        "    mean_rating = driver_df['safty_rating'].mean()\n",
        "    safty_rating_mean.fillna(mean_rating, inplace=True)\n",
        "\n",
        "\n",
        "d1 = driver_df.groupby('policy_id', as_index=False)['safty_rating'].mean().rename(columns={'safty_rating': 'safty_rating_mean'})\n",
        "\n",
        "driver_df = pd.merge(driver_df,d1, on='policy_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVUtUyJTBfRH"
      },
      "outputs": [],
      "source": [
        "driver_df.drop(['safty_rating'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpKJKCEqqoSr",
        "outputId": "f619c9c7-981f-48e5-e1e3-25a7431e6448"
      },
      "outputs": [],
      "source": [
        "bins = [-float('inf'), 20, 40, 60, 80, float('inf')]\n",
        "\n",
        "labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
        "\n",
        "driver_df['safety_mean_cat'] = pd.cut(driver_df['safty_rating_mean'], bins=bins, labels=labels)\n",
        "\n",
        "# Check the distribution of the new column\n",
        "driver_df['safety_mean_cat'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-IIQCzrqoN6"
      },
      "outputs": [],
      "source": [
        "driver_df = pd.get_dummies(driver_df, columns = ['safety_mean_cat' ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iax9YLziqoJU"
      },
      "outputs": [],
      "source": [
        "driver_df.drop(['safty_rating_mean'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8sy9pBoqn_k"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vehicles Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MhRsBmUmfuc_",
        "outputId": "a5fb2daa-49e6-4162-a534-5e9ad5c70c13"
      },
      "outputs": [],
      "source": [
        "vehicle_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5YLw5OhqUTC-",
        "outputId": "f06cec37-89bb-460b-f58c-62b6519ef47d"
      },
      "outputs": [],
      "source": [
        "vehicle_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ugsuqni0nQ",
        "outputId": "0493c46f-f95f-4966-f35c-ac76db296f71"
      },
      "outputs": [],
      "source": [
        "vehicle_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e16_TZ9wmPYR",
        "outputId": "194cc0f8-aa69-476f-f704-05c99b04d209"
      },
      "outputs": [],
      "source": [
        "vehicle_df.drop(['make_model'], axis = 1, inplace = True)\n",
        "vehicle_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "IqhEvwna6w0G",
        "outputId": "46f64dba-5be6-4fa2-8ee8-2db31857eb65"
      },
      "outputs": [],
      "source": [
        "vehicle_df = pd.get_dummies(vehicle_df, columns = ['ownership_type', 'color' ])\n",
        "vehicle_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSv_que8jVFc"
      },
      "outputs": [],
      "source": [
        "bool_cols1 = [col for col in vehicle_df \n",
        "              if np.isin(vehicle_df[col].dropna().unique(), [0, 1]).all()]\n",
        "bool_cols1\n",
        "age_mean = vehicle_df['age']\n",
        "if age_mean.isnull().values.any():\n",
        "    mean_age = vehicle_df['age'].mean()\n",
        "    age_mean.fillna(mean_age, inplace=True)\n",
        "\n",
        "\n",
        "d1 = vehicle_df.groupby('policy_id', as_index=False)['age'].mean().rename(columns={'age': 'age_mean'})\n",
        "\n",
        "vehicle_df = pd.merge(vehicle_df,d1, on='policy_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgMxH5xPCc_9",
        "outputId": "1133ba11-a8a8-4505-c567-843eaef21dd8"
      },
      "outputs": [],
      "source": [
        "vehicle_df['age_mean'].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51Y-KWCjCgZC"
      },
      "outputs": [],
      "source": [
        "vehicle_df['age_mean'].fillna(vehicle_df['age_mean'].mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rye-565VjU76",
        "outputId": "23b4489d-e41a-45fe-d72f-e856e395cef0"
      },
      "outputs": [],
      "source": [
        "vehicle_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1FHpp-dsIPA",
        "outputId": "c8556959-22e4-4305-d74c-0d77f3dfd0fd"
      },
      "outputs": [],
      "source": [
        "na_values = vehicle_df['age_mean'].isna().sum()\n",
        "print(\"Number of NA values in age_class column:\", na_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nopcgECXsVzA",
        "outputId": "06986756-dbf6-42d3-9ea8-65ee03d6bb24"
      },
      "outputs": [],
      "source": [
        "age_bins = [0, 4, 8, 12, 16]\n",
        "\n",
        "age_labels = ['age_0_4', 'age_4_8', 'age_8_12', 'age_12_16']\n",
        "\n",
        "vehicle_df['age_class'] = pd.cut(vehicle_df['age_mean'], bins=age_bins, labels=age_labels)\n",
        "\n",
        "print(vehicle_df['age_class'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9FK_BgJsC8J",
        "outputId": "3990377d-c394-4be7-cee1-43083ac17a08"
      },
      "outputs": [],
      "source": [
        "na_values = vehicle_df['age_class'].isna().sum()\n",
        "\n",
        "print(\"Number of NA values in age_class column:\", na_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA6cLlHosuJS"
      },
      "outputs": [],
      "source": [
        "vehicle_df['age_class'].fillna('age_4_8', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pd4SARPsylR",
        "outputId": "80b09d2b-fdba-48e4-e5ac-46caec21b809"
      },
      "outputs": [],
      "source": [
        "na_valuesa = vehicle_df['age_class'].isna().sum()\n",
        "\n",
        "print(\"Number of NA values in age_class column:\", na_valuesa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC_0FAVmtlTZ"
      },
      "outputs": [],
      "source": [
        "vehicle_df = pd.get_dummies(vehicle_df, columns = ['age_class' ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1mcC7Oh_uNai",
        "outputId": "83303106-b750-4c1e-942a-cfb2d6ade3e0"
      },
      "outputs": [],
      "source": [
        "vehicle_df.drop(['age_mean'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Xg5sED5JjR_7",
        "outputId": "52373485-4018-49a2-a34b-49eb80922a7d"
      },
      "outputs": [],
      "source": [
        "policydriver = pd.merge(left = policy_df, right = driver_df, how = 'inner', on = 'policy_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "DrsmiBw-jR7R",
        "outputId": "f5b0c982-0ebc-4aa0-bbd3-e7e2ce439992"
      },
      "outputs": [],
      "source": [
        "pdv_df= pd.merge(left = policydriver, right = vehicle_df, how = 'inner', on = 'policy_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Izoxzp7M7gY_",
        "outputId": "cba5d05c-e67d-42ae-dc19-7bc88583f7a5"
      },
      "outputs": [],
      "source": [
        "pdv_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "V_X1FCZCjR3V",
        "outputId": "43975442-f3c3-46c3-83b5-1581cb82f537"
      },
      "outputs": [],
      "source": [
        "pdv_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rWok_o8jRzx",
        "outputId": "7f768d9d-95d6-4de0-f3d7-2bbd2e4e6e8e"
      },
      "outputs": [],
      "source": [
        "pdv_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAABRK6f7r4f",
        "outputId": "473f1569-6b06-485b-817b-fab875869d87"
      },
      "outputs": [],
      "source": [
        "pdv_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfyraCcRjRvr",
        "outputId": "850255cf-f1a0-4094-f009-0efd68f6b0e4"
      },
      "outputs": [],
      "source": [
        "np.shape(pdv_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIRbCHiljRn0"
      },
      "outputs": [],
      "source": [
        "pdv_df.to_csv('pvd_XGB_RF.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset=pdv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "issued = Dataset[Dataset['convert_ind']==1]\n",
        "ntissued = Dataset[Dataset['convert_ind']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Method1 \n",
        "np.random.seed(123)\n",
        "issued_sample1 = issued.sample(4118)\n",
        "ntissued_sample1 = ntissued.sample(4118)\n",
        "Dataset1 = pd.concat([issued_sample1,ntissued_sample1],axis=0,ignore_index=True)\n",
        "Dataset1 = Dataset1.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Method2\n",
        "issued = Dataset[Dataset['convert_ind']==1]\n",
        "ntissued = Dataset[Dataset['convert_ind']==0]\n",
        "np.random.seed(123)\n",
        "issued_sample2 = issued.sample(np.shape(issued)[0])\n",
        "ntissued_sample2 = ntissued.sample(np.shape(ntissued)[0])\n",
        " \n",
        "Dataset2 = pd.concat([issued_sample2,ntissued_sample2],axis=0,ignore_index=True)\n",
        "Dataset2 = Dataset2.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.shape(issued)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y1 =Dataset1['convert_ind']\n",
        "X1 =Dataset1.drop(['convert_ind','policy_id'], axis = 1)\n",
        "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, test_size=0.3, random_state=42)\n",
        "X_train1, X_val1, Y_train1, Y_val1 = train_test_split(X_train1, Y_train1, test_size=0.15, random_state=42)\n",
        "X_train1 = X_train1.astype('float32')\n",
        "Y_train1 = Y_train1.astype('float32')\n",
        "X_val1 = X_val1.astype('float32')\n",
        "Y_val1 = Y_val1.astype('float32')\n",
        "X_test1 = X_test1.astype('float32')\n",
        "Y_test1 = Y_test1.astype('float32')\n",
        "print('Training set shape:', X_train1.shape, Y_train1.shape)\n",
        "print('Validation set shape:', X_val1.shape, Y_val1.shape)\n",
        "print('Testing set shape:', X_test1.shape, Y_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y2 =Dataset2['convert_ind']\n",
        "X2 =Dataset2.drop(['convert_ind','policy_id'], axis = 1)\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.3, random_state=42)\n",
        "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train2, Y_train2, test_size=0.15, random_state=42)\n",
        "X_train2 = X_train2.astype('float32')\n",
        "Y_train2 = Y_train2.astype('float32')\n",
        "X_val2 = X_val2.astype('float32')\n",
        "Y_val2 = Y_val2.astype('float32')\n",
        "X_test2 = X_val2.astype('float32')\n",
        "Y_test2 = Y_val2.astype('float32')\n",
        "print('Training set shape:', X_train2.shape, Y_train2.shape)\n",
        "print('Validation set shape:', X_val2.shape, Y_val2.shape)\n",
        "print('Testing set shape:', X_test2.shape, Y_test2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train1.isna().sum())\n",
        "print(X_train1.isna().any().any())\n",
        "print(X_train1[X_train1.isna().any(axis=1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_with_missing1 = X_train1.columns[X_train1.isna().any()].tolist()\n",
        "cols_with_missing1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train2.isna().sum())\n",
        "print(X_train2.isna().any().any())\n",
        "print(X_train2[X_train2.isna().any(axis=1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_with_missing2 = X_train2.columns[X_train2.isna().any()].tolist()\n",
        "cols_with_missing2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DNN\n",
        "\n",
        "We implemented DNN and use \"RandomizedSearchCV\" and \"GridSearchCV\" for fine tuning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing RandomizedSearchCV method for DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "\n",
        "def create_dnn_model(hidden_layers=1, neurons=128, dropout_rate=0.5, l2_lambda=0.01, use_batchnorm=False, activation=\"relu\", optimizer =\"adam\"):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(neurons, activation=activation, input_dim=X_train1.shape[1], kernel_regularizer=l2(l2_lambda)))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Dropout(dropout_rate))\n",
        "    for i in range(hidden_layers):\n",
        "        dnn_model.add(Dense(neurons, activation=activation, kernel_regularizer=l2(l2_lambda)))\n",
        "        if use_batchnorm:\n",
        "            dnn_model.add(BatchNormalization())\n",
        "        dnn_model.add(Dropout(dropout_rate))\n",
        "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
        "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "\n",
        "# Define the hyperparameters for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    \"hidden_layers\": range(1, 6),\n",
        "    \"neurons\": range(5, 30),\n",
        "    \"dropout_rate\":[0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    \"l2_lambda\": [0.01, 0.1, 1],\n",
        "    \"use_batchnorm\": [False, True],\n",
        "    \"activation\": [\"relu\", \"tanh\"],\n",
        "    \"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"]\n",
        "}\n",
        "\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1_score': make_scorer(f1_score)}\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.0001\n",
        "    for i in range(1, 2):\n",
        "        if epoch >= 250 * i:\n",
        "            lr /= 2\n",
        "    print(f'Learning rate at epoch {epoch}: {lr}')\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "dnn_model = KerasClassifier(build_fn=create_dnn_model, verbose=1, epochs=500)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=dnn_model, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring=scoring, refit='accuracy')\n",
        "random_result = random_search.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "best_model = random_result.best_estimator_.model\n",
        "history = best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "results_df = pd.DataFrame(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "best_model = create_dnn_model(**random_search.best_params_)\n",
        "best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256,\n",
        "                         shuffle=True)\n",
        "\n",
        "print(f\"Best parameters: {random_search.best_params_}\")\n",
        "print(f\"Best score: {random_search.best_score_}\")\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "with open('rnd_best_parameters.txt', 'w') as f:\n",
        "    f.write(str(random_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_DNN_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(Y_test1, y_pred_DNN_binary_rnd))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(Y_test1, y_pred_DNN_binary_rnd)\n",
        "print(cm)\n",
        "\n",
        "# Save predictions and true labels to CSV files\n",
        "pd.DataFrame({'y_pred': y_pred_DNN_binary_rnd.ravel()}).to_csv('ypred_DNN_rnd.csv', index=False)\n",
        "pd.DataFrame({'Y_test': Y_test1}).to_csv('Y_test.csv', index=False)\n",
        "\n",
        "# Plot train and validation loss values\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot train and validation accuracy values\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(train_acc, label='Train Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing GridSearchCV method for DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def create_model(hidden_layers=1, neurons=8, dropout_rate=0.1, l2_lambda=0.01, use_batchnorm=False, activation='relu', optimizer='adam'):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(neurons, activation=activation, input_dim=X_train1.shape[1], kernel_initializer='glorot_uniform', kernel_regularizer=l2(l2_lambda)))\n",
        "    if use_batchnorm:\n",
        "        dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Dropout(dropout_rate))\n",
        "    for i in range(hidden_layers):\n",
        "        dnn_model.add(Dense(neurons, kernel_initializer='glorot_uniform', kernel_regularizer=l2(l2_lambda)))\n",
        "        if use_batchnorm:\n",
        "            dnn_model.add(BatchNormalization())\n",
        "        dnn_model.add(Dropout(dropout_rate))\n",
        "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=128, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "param_grid = {\n",
        "    \"hidden_layers\": [1, 2, 3, 4],\n",
        "    \"neurons\": [8, 16, 32],\n",
        "    \"dropout_rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "    \"l2_lambda\": [0.01, 0.1],\n",
        "    \"use_batchnorm\": [False, True],\n",
        "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
        "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
        "}\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.0001\n",
        "    for i in range(1, 2):\n",
        "        if epoch >= 250 * i:\n",
        "            lr /= 2\n",
        "    print(f'Learning rate at epoch {epoch}: {lr}')\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "dnn_model = KerasClassifier(build_fn=create_dnn_model, verbose=1, epochs=500)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, \n",
        "                       batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "best_model = grid_result.best_estimator_.model\n",
        "history = best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300,\n",
        "                          batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "results_df = pd.DataFrame(grid.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "best_model = create_dnn_model(**grid.best_params_)\n",
        "best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256,\n",
        "                         shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Best parameters: {grid.best_params_}\")\n",
        "print(f\"Best score: {grid.best_score_}\")\n",
        "\n",
        "# Save results in CSV file\n",
        "results_df = pd.DataFrame.from_dict(grid.cv_results_)\n",
        "results_df.to_csv('grid_search_results.csv', index=False)\n",
        "\n",
        "# Save best parameters in txt file\n",
        "with open('grid_best_parameters.txt', 'w') as f:\n",
        "    f.write(str(grid.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_DNN_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(Y_test1, y_pred_DNN_binary_grid))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(Y_test1, y_pred_DNN_binary_grid)\n",
        "print(cm)\n",
        "\n",
        "# Save predictions and true labels to CSV files\n",
        "pd.DataFrame({'y_pred': y_pred_DNN_binary_grid.ravel()}).to_csv('ypred_DNN_grid.csv', index=False)\n",
        "#pd.DataFrame({'Y_test': Y_test}).to_csv('Y_test.csv', index=False)\n",
        "\n",
        "# Plot train and validation loss values\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot train and validation accuracy values\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(train_acc, label='Train Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install xgboost\n",
        "#pip install scipy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GridSearchCV for XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8UC7aIL_1vj",
        "outputId": "ed3771b6-9288-463a-d044-3f7b2b290260"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [10, 20],\n",
        "    'learning_rate': [0.001, 0.05],\n",
        "    'n_estimators': [ 1000,2000,5000],\n",
        "    'min_child_weight': [ 20,10],\n",
        "    'subsample': [0.5,0.8],\n",
        "    'colsample_bytree': [1.0, 0.8,0.1],\n",
        "    'gamma': [ 0.2,0.5],\n",
        "    'reg_alpha': [ 0.1,0.5],\n",
        "    'reg_lambda': [ 2,5],\n",
        "}\n",
        "\n",
        "grid_search_XGB = GridSearchCV(estimator=xgb_model, param_grid=param_grid, n_jobs=-1, verbose=1,cv=2)\n",
        "grid_search_XGB.fit(X_train1, Y_train1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Best hyperparameters: \", grid_search_XGB.best_params_)\n",
        "print(\"Best score: \", grid_search_XGB.best_score_)\n",
        "\n",
        "best_model = grid_search_XGB.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test1)\n",
        "\n",
        "\n",
        "# Convert y_pred from probabilities to binary predictions\n",
        "y_pred_XGB_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_XGB_binary_grid))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_XGB_binary_grid))\n",
        "\n",
        "# Save the XGB predictions to a CSV file\n",
        "y_pred = pd.DataFrame(y_pred_XGB_binary_grid)\n",
        "y_pred.to_csv('y_pred_XGB_binary_grid.csv', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RandomizedSearchCV for XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define the model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Define hyperparameters and their values for tuning\n",
        "param_dist = {\n",
        "    'max_depth': randint(1, 30),\n",
        "    'learning_rate': uniform(0.001, 0.1),\n",
        "    'n_estimators': randint(6998, 7000),\n",
        "    'min_child_weight': randint(1, 30),\n",
        "    'subsample': uniform(0.1, 0.9),\n",
        "    'colsample_bytree': uniform(0.1, 0.9),\n",
        "    'gamma': uniform(0, 1),\n",
        "    'reg_alpha': uniform(0, 1),\n",
        "    'reg_lambda': uniform(1, 10),\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters\n",
        "random_search_XGB = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_jobs=-1, verbose=2, n_iter=100, cv=5)\n",
        "random_search_XGB.fit(X_train1, Y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Best hyperparameters: \", random_search_XGB.best_params_)\n",
        "print(\"Best score: \", random_search_XGB.best_score_)\n",
        "\n",
        "best_model = random_search_XGB.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test1)\n",
        "\n",
        "\n",
        "# Convert y_pred from probabilities to binary predictions\n",
        "y_pred_XGB_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_XGB_binary_rnd))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_XGB_binary_rnd))\n",
        "\n",
        "# Save the XGB predictions to a CSV file\n",
        "y_pred = pd.DataFrame(y_pred_XGB_binary_rnd)\n",
        "y_pred.to_csv('y_pred_XGB_binary_rnd.csv', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ranndom Forest, RF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RandomizedSearchCV for RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': range(100, 3000),\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "random_search_RF = RandomizedSearchCV(rf, param_distributions=param_distributions, n_iter=100, cv=5)\n",
        "random_search_RF.fit(X_train1, Y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters: \", random_search_RF.best_params_)\n",
        "print(\"Best score: \", random_search_RF.best_score_)\n",
        "\n",
        "best_model = random_search_RF.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_RF_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_RF_binary_rnd))\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_RF_binary_rnd))\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred_RF_binary_rnd)\n",
        "y_pred.to_csv('y_pred_RF_binary_rnd.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GridSearchCV for RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [500100, 1000, 2000],\n",
        "    'max_depth': [5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [2, 4,6],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "grid_search_RF = GridSearchCV(rf, param_grid=param_grid, cv=2)\n",
        "grid_search_RF.fit(X_train1, Y_train1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters: \", grid_search_RF.best_params_)\n",
        "print(\"Best score: \", grid_search_RF.best_score_)\n",
        "\n",
        "best_model = grid_search_RF.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_RF_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_RF_binary_grid))\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_RF_binary_grid))\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred_RF_binary_grid)\n",
        "y_pred.to_csv('y_pred_RF_binary_grid.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_DNNg= y_pred_DNN_binary_grid\n",
        "Y_pred_DNNr= y_pred_DNN_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_XGBg= y_pred_XGB_binary_grid\n",
        "Y_pred_XGBr= y_pred_XGB_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_RFg= y_pred_RF_binary_grid\n",
        "Y_pred_RFr= y_pred_RF_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "preds = np.hstack([Y_pred_DNNg.to_numpy().reshape(-1, 1), Y_pred_XGBg.to_numpy().reshape(-1, 1), Y_pred_RFg.to_numpy().reshape(-1, 1)])\n",
        "ensemble_preds = mode(preds, axis=1)[0]\n",
        "ensemble_preds = ensemble_preds.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "ensemble_preds = np.array(ensemble_preds)\n",
        "cm = confusion_matrix(Y_test1, ensemble_preds)\n",
        "report = classification_report(Y_test1, ensemble_preds)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "preds = np.hstack([Y_pred_DNNr.to_numpy().reshape(-1, 1), Y_pred_XGBr.to_numpy().reshape(-1, 1), Y_pred_RFr.to_numpy().reshape(-1, 1)])\n",
        "ensemble_preds = mode(preds, axis=1)[0]\n",
        "ensemble_preds = ensemble_preds.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "ensemble_preds = np.array(ensemble_preds)\n",
        "cm = confusion_matrix(Y_test1, ensemble_preds)\n",
        "report = classification_report(Y_test1, ensemble_preds)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
