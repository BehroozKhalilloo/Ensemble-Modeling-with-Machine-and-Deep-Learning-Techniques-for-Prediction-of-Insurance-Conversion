{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xGLxiF7lrns"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeghhyxlGnxq"
      },
      "outputs": [],
      "source": [
        "policy_df =pd.read_csv('policies.csv')\n",
        "driver_df =pd.read_csv('drivers.csv')\n",
        "vehicle_df =pd.read_csv('vehicles.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OrqHGQ04kJW"
      },
      "outputs": [],
      "source": [
        "driver_df =pd.read_csv('drivers.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A44N6GguL6D",
        "outputId": "b3afb484-bf65-4b34-ce80-8b44a3a29ee6"
      },
      "outputs": [],
      "source": [
        "np.shape(policy_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The real dataset have column named \"split\" for splitting Train and test sets. But because we want to check the accuracy, and I should have the real value for response variable of test dataset, I just divided the main training set to train and test sets, which we will see in the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91hvdqbzuEc8"
      },
      "outputs": [],
      "source": [
        "policy_df = policy_df[policy_df['split'] == \"Train\"]\n",
        "\n",
        "#tarining_full = policy_df[policy_df['split'] == \"Train\"]\n",
        "#train_df = policy_df[policy_df['split'] == \"Train\"]\n",
        "#test_df  = policy_df[policy_df['split'] == \"Test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YPR59gHoboL"
      },
      "outputs": [],
      "source": [
        "policy_df =pd.read_csv('policies.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wts_IzvuRts",
        "outputId": "788a14b0-fd15-4707-9311-98c28aabce19"
      },
      "outputs": [],
      "source": [
        "np.shape(policy_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "NNr3-W0Hf2LH",
        "outputId": "8ca453e8-e049-42cc-a4a0-f23afcaacf4b"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Y0vI-Kuje-2W",
        "outputId": "60ded0e5-c8d7-4a42-a857-bdf9964cd7f6"
      },
      "outputs": [],
      "source": [
        "policy_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJlqepyzixd5",
        "outputId": "123358a9-ad5f-4ba9-a433-34daeed2e6f7"
      },
      "outputs": [],
      "source": [
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvjDusgZuj-E",
        "outputId": "69d2fceb-80aa-4e43-9e9f-e209a7ae12e8"
      },
      "outputs": [],
      "source": [
        "policy_df.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I removed unneccesary variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF6Zls6Euj3F",
        "outputId": "84e68687-ab30-419d-be6c-05ce68fe75f5"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['Unnamed: 0','Agent_cd','zip','state_id', 'county_name','CAT_zone', 'split'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnOoEPPyvnk-",
        "outputId": "66ccd027-a61c-4ace-ef11-6eb003748579"
      },
      "outputs": [],
      "source": [
        "policy_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = policy_df[['total_number_veh', 'num_loaned_veh', 'num_owned_veh','num_leased_veh']].corr()\n",
        "print(corr_matrix)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a column which is named 'total_number_veh' which are sum of the 'num_loaned_veh', 'num_owned_veh', 'num_leased_veh' columns and because of high corrocaltion, I removed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbWN1mrrujo_",
        "outputId": "02ebe067-89ea-44cd-a272-d8693960ee2a"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['num_loaned_veh', 'num_owned_veh', 'num_leased_veh'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Z8vbYy5QwGRL",
        "outputId": "f73ec20c-911f-452c-c6bb-4513ac21d514"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I change the date of qoute to quarters as a categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEXXbTnDujiZ"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "policy_df['Quote_dt'] = pd.to_datetime(policy_df['Quote_dt'])\n",
        "#policy_df['Quote_month'] = policy_df['Quote_dt'].dt.month\n",
        "policy_df['Quote_quarter'] = policy_df['Quote_dt'].dt.quarter\n",
        "#policy_df['Quote_year'] = policy_df['Quote_dt'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxMwDnEujcL",
        "outputId": "d0866de7-2638-41a4-f4a3-bd64387a6b32"
      },
      "outputs": [],
      "source": [
        "policy_df.drop(['Quote_dt'], axis = 1, inplace = True)\n",
        "policy_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "37IqMj3Uw9EV",
        "outputId": "c49e94d9-0de2-4596-d994-03a0e842f073"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed_dmm7tzoGv",
        "outputId": "152ea955-0db3-4da9-ec55-ee100b015e1c"
      },
      "outputs": [],
      "source": [
        "policy_df['primary_parking'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk0ML_K8zoCE",
        "outputId": "20eac8af-121b-4361-ee91-cc092733941e"
      },
      "outputs": [],
      "source": [
        "policy_df['Cov_package_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDgdb1h3w8_R",
        "outputId": "92f55082-fde1-42ea-9ee4-746eb3d8f818"
      },
      "outputs": [],
      "source": [
        "policy_df['Prior_carrier_grp'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "V5fjfK7G1Nd1",
        "outputId": "a8371fad-5503-4161-c6f3-e9852115c2e8"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "oKSE5RmdzKy5",
        "outputId": "8cec7cb2-de31-4ce0-b594-05c37ec5c134"
      },
      "outputs": [],
      "source": [
        "policy_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ueBUlIzKtg",
        "outputId": "c518bc8d-fafe-4763-b1b7-b159e886dcd9"
      },
      "outputs": [],
      "source": [
        "policy_df.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Encoding categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6QsNonbzKpC"
      },
      "outputs": [],
      "source": [
        "policy_df = pd.get_dummies(policy_df, columns = ['discount','Home_policy_ind','Prior_carrier_grp','Cov_package_type',\n",
        "                                                  'Quote_quarter', 'primary_parking'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e89njPAU0pj1",
        "outputId": "5601de69-bb9e-4ea8-d417-caf2560070d1"
      },
      "outputs": [],
      "source": [
        "policy_df['quote'] = policy_df['quoted_amt'].str.replace(',','')\n",
        "policy_df['quote'] = policy_df['quote'].str.replace('$','')\n",
        "policy_df['quote'] = pd.to_numeric(policy_df['quote'], errors='coerce')\n",
        "policy_df['quote'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "UQ0jXhkWzKi6",
        "outputId": "11615682-d86b-4573-87c7-32473cbd6227"
      },
      "outputs": [],
      "source": [
        "#policy_df.describe()\n",
        "policy_df.head()\n",
        "#policy_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkkDagxezKd_",
        "outputId": "dd704e8e-28a3-434f-b58b-4bc623bba0ee"
      },
      "outputs": [],
      "source": [
        "np.shape(policy_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy_df['quoted_amt'] = policy_df['quoted_amt'].str.replace(',','')\n",
        "policy_df['quoted_amt'] = policy_df['quoted_amt'].str.replace('$','')\n",
        "policy_df['quoted_amt'] = pd.to_numeric(policy_df['quoted_amt'], errors='coerce')\n",
        "policy_df['quoted_amt'].dtype"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Policy Datset Cleaned "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQW7bpzfzKYN",
        "outputId": "7b7d13c6-3c9b-4fa3-a19a-bf2e4d5742c1"
      },
      "outputs": [],
      "source": [
        "policy_df.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Drivers Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KPSlGn7QfyhG",
        "outputId": "f92beee4-a054-46f3-aa69-ba4392ce98c6"
      },
      "outputs": [],
      "source": [
        "driver_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_0xf2oF6Gnq6",
        "outputId": "a7c6f2c7-cb78-4a10-8881-efda3f5dd61a"
      },
      "outputs": [],
      "source": [
        "driver_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6o-ZbgW3-RO",
        "outputId": "99685404-29f6-4e51-f5a0-fa15b233a86c"
      },
      "outputs": [],
      "source": [
        "driver_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnMQ22uiiuvR",
        "outputId": "0935010d-99b3-40e5-d9dc-ea35fe197e46"
      },
      "outputs": [],
      "source": [
        "driver_df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Age 100 does not make sense for drivers. Just deleting drivers with age greater than 100!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ob2zQu-Tlcuc",
        "outputId": "fd19103b-0e7f-4bd1-985c-6177a32c6a02"
      },
      "outputs": [],
      "source": [
        "driver_df[driver_df['age']>100].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMsd7VYAlcqI"
      },
      "outputs": [],
      "source": [
        "driver_df = driver_df.drop(driver_df[driver_df['age'] > 100].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UtGAaRvsngQf",
        "outputId": "45389469-b613-4c0d-99d0-16a873b2afd4"
      },
      "outputs": [],
      "source": [
        "driver_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Encoding categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "WRjMjV-BngHf",
        "outputId": "14a6bec6-ddf6-4659-a7c2-6342a104f09a"
      },
      "outputs": [],
      "source": [
        "driver_df = pd.get_dummies(driver_df, columns = ['gender', 'living_status' ,'high_education_ind'])\n",
        "driver_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For some policies, there are several drivers with different safety rating which we group them by mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiAA_A2fqobQ"
      },
      "outputs": [],
      "source": [
        "bool_cols1 = [col for col in driver_df \n",
        "              if np.isin(driver_df[col].dropna().unique(), [0, 1]).all()]\n",
        "bool_cols1\n",
        "safty_rating_mean = driver_df['safty_rating']\n",
        "if safty_rating_mean.isnull().values.any():\n",
        "    mean_rating = driver_df['safty_rating'].mean()\n",
        "    safty_rating_mean.fillna(mean_rating, inplace=True)\n",
        "\n",
        "\n",
        "d1 = driver_df.groupby('policy_id', as_index=False)['safty_rating'].mean().rename(columns={'safty_rating': 'safty_rating_mean'})\n",
        "\n",
        "driver_df = pd.merge(driver_df,d1, on='policy_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meVVpsrf7C9a"
      },
      "outputs": [],
      "source": [
        "driver_df.drop(['safty_rating'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "heFEqJmE7C9a",
        "outputId": "2903b190-6b38-4678-973c-77f7657e18a5"
      },
      "outputs": [],
      "source": [
        "driver_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "AUL8hphPqoW9",
        "outputId": "8e66c2a7-11a2-4600-b957-fc799decb1b6"
      },
      "outputs": [],
      "source": [
        "driver_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX7UPZEyngCB"
      },
      "outputs": [],
      "source": [
        "# Vehicles Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MhRsBmUmfuc_",
        "outputId": "76b107ab-197c-422d-f3b2-886d354cb6ef"
      },
      "outputs": [],
      "source": [
        "vehicle_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5YLw5OhqUTC-",
        "outputId": "9621d561-2e08-431d-ec61-5289f7a5b218"
      },
      "outputs": [],
      "source": [
        "vehicle_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ugsuqni0nQ",
        "outputId": "c3cfbd42-05be-4a99-df79-6695ec2e373c"
      },
      "outputs": [],
      "source": [
        "vehicle_df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just dropping 'make_model', 'color' columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e16_TZ9wmPYR",
        "outputId": "ae0188e5-a0eb-46dc-a7d8-fddbf6baaf63"
      },
      "outputs": [],
      "source": [
        "vehicle_df.drop(['make_model', 'color' ], axis = 1, inplace = True)\n",
        "vehicle_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IqhEvwna6w0G",
        "outputId": "91512277-9c27-400c-c4e3-31008ff1149d"
      },
      "outputs": [],
      "source": [
        "vehicle_df = pd.get_dummies(vehicle_df, columns = ['ownership_type'])\n",
        "vehicle_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For some policies, there are several vehicles with different ages which we group them by mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSv_que8jVFc"
      },
      "outputs": [],
      "source": [
        "bool_cols1 = [col for col in vehicle_df \n",
        "              if np.isin(vehicle_df[col].dropna().unique(), [0, 1]).all()]\n",
        "bool_cols1\n",
        "age_mean = vehicle_df['age']\n",
        "if age_mean.isnull().values.any():\n",
        "    mean_age = vehicle_df['age'].mean()\n",
        "    age_mean.fillna(mean_age, inplace=True)\n",
        "\n",
        "\n",
        "d1 = vehicle_df.groupby('policy_id', as_index=False)['age'].mean().rename(columns={'age': 'age_mean'})\n",
        "\n",
        "vehicle_df = pd.merge(vehicle_df,d1, on='policy_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rye-565VjU76",
        "outputId": "9b718cdd-9780-4100-c0a3-b122a53fa58c"
      },
      "outputs": [],
      "source": [
        "vehicle_df.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging Policy and Driver Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Xg5sED5JjR_7",
        "outputId": "d462e180-7c4f-47d8-f9e8-f9b5f2018f55"
      },
      "outputs": [],
      "source": [
        "policydriver = pd.merge(left = policy_df, right = driver_df, how = 'inner', on = 'policy_id')\n",
        "policydriver.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merging Vehicles Dataset with merged dataset of Policy and Driver Datasets, named pvd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "DrsmiBw-jR7R",
        "outputId": "01cedccf-127a-4b1c-a91d-253e1da00340"
      },
      "outputs": [],
      "source": [
        "pdv_df= pd.merge(left = policydriver, right = vehicle_df, how = 'inner', on = 'policy_id')\n",
        "pdv_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "Izoxzp7M7gY_",
        "outputId": "448549f2-38cf-4a80-d9d6-0e0d4f81882b"
      },
      "outputs": [],
      "source": [
        "pdv_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "V_X1FCZCjR3V",
        "outputId": "b998f8d3-f9a3-4e44-e7ab-541ab2c4a3ea"
      },
      "outputs": [],
      "source": [
        "pdv_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rWok_o8jRzx",
        "outputId": "1169d129-d4b0-4aa9-b5fe-63e9bc2d2924"
      },
      "outputs": [],
      "source": [
        "pdv_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAABRK6f7r4f",
        "outputId": "ec4ede4a-0710-4788-d288-2c158c868641"
      },
      "outputs": [],
      "source": [
        "pdv_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfyraCcRjRvr",
        "outputId": "d5b19152-5fc2-4982-b6da-48e569cc0960"
      },
      "outputs": [],
      "source": [
        "np.shape(pdv_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "by2h6V53zBSZ",
        "outputId": "73ff3b11-2f7d-4c4a-ad1c-578c45ea7490"
      },
      "outputs": [],
      "source": [
        "pdv_df = pdv_df.drop(['policy_id'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGtX7b-A5gK",
        "outputId": "74175534-435e-49da-a9ab-857cc8653b1a"
      },
      "outputs": [],
      "source": [
        "pdv_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqTFMciICaqI",
        "outputId": "5dbc88d9-bf88-4ab6-bf28-c2ffb392efba"
      },
      "outputs": [],
      "source": [
        "pdv_df['convert_ind']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdv_df.to_csv('pvd_DNN.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset=pdv_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using MinMaxScaler Scaler for numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVY2yq0gkg0C"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "cols_to_scale = ['credit_score', 'quoted_amt','number_drivers',\t'total_number_veh', 'age_mean', 'safty_rating_mean']\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(Dataset[cols_to_scale])\n",
        "Dataset[cols_to_scale] = scaler.transform(Dataset[cols_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7veQmOxEZNg"
      },
      "outputs": [],
      "source": [
        "Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset is imbalanced. Response is 0 or 1 where about 89% are 0 and 11% are 1.\n",
        "Here we can implement two diffeerent method for trainig data.\n",
        "Mehtod 1:\n",
        "Selecting same number of sample from two classes\n",
        "\n",
        "Method 2:\n",
        "Useing the main imbalanced dataset and implement weighted loss function and/or weight for data, specific weights for each class."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WScIKkoxg7H"
      },
      "outputs": [],
      "source": [
        "issued = Dataset[Dataset['convert_ind']==1]\n",
        "ntissued = Dataset[Dataset['convert_ind']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiHBO4h4Ecrg",
        "outputId": "a463448f-d027-4206-8483-a0403099e53f"
      },
      "outputs": [],
      "source": [
        "np.shape(issued)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woq-KVhiEdDC",
        "outputId": "da9742f3-deed-4ff5-d09f-8a05e6bb2018"
      },
      "outputs": [],
      "source": [
        "np.shape(ntissued)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNuXacmPEbnh"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123)\n",
        "issued_sample1 = issued.sample(4118)\n",
        "ntissued_sample1 = ntissued.sample(4118)\n",
        "Dataset1 = pd.concat([issued_sample1,ntissued_sample1],axis=0,ignore_index=True)\n",
        "Dataset1 = Dataset1.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3GkXtbAQ-iZ"
      },
      "outputs": [],
      "source": [
        "issued = Dataset[Dataset['convert_ind']==1]\n",
        "ntissued = Dataset[Dataset['convert_ind']==0]\n",
        "np.random.seed(123)\n",
        "issued_sample2 = issued.sample(np.shape(issued)[0])\n",
        "ntissued_sample2 = ntissued.sample(np.shape(ntissued)[0])\n",
        " \n",
        "Dataset2 = pd.concat([issued_sample2,ntissued_sample2],axis=0,ignore_index=True)\n",
        "Dataset2 = Dataset2.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting Dataset based on  method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB84eLaiRBJI"
      },
      "outputs": [],
      "source": [
        "Y1 =Dataset1['convert_ind']\n",
        "X1 =Dataset1.drop(['convert_ind','policy_id'], axis = 1)\n",
        "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, test_size=0.3, random_state=42)\n",
        "X_train1, X_val1, Y_train1, Y_val1 = train_test_split(X_train1, Y_train1, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Training set shape:', X_train1.shape, Y_train1.shape)\n",
        "print('Validation set shape:', X_val1.shape, Y_val1.shape)\n",
        "print('Testing set shape:', X_test1.shape, Y_test1.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting Dataset based on  method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFK7Lt-lRFDu",
        "outputId": "e7eb4480-9268-42fb-c421-17e14af59959"
      },
      "outputs": [],
      "source": [
        "Y2 =Dataset2['convert_ind']\n",
        "X2 =Dataset2.drop(['convert_ind','policy_id'], axis = 1)\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, test_size=0.3, random_state=42)\n",
        "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train2, Y_train2, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Training set shape:', X_train2.shape, Y_train2.shape)\n",
        "print('Validation set shape:', X_val2.shape, Y_val2.shape)\n",
        "print('Testing set shape:', X_test2.shape, Y_test2.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cheching for any NA in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOF1dQdhgpKK",
        "outputId": "5163347d-6b92-490f-e582-8090c68f3723"
      },
      "outputs": [],
      "source": [
        "print(X_train1.isna().sum())\n",
        "print(X_train1.isna().any().any())\n",
        "print(X_train1[X_train1.isna().any(axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_with_missing1 = X_train1.columns[X_train1.isna().any()].tolist()\n",
        "cols_with_missing1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pHs-Zolg-FK",
        "outputId": "c57b4aea-21c3-4b44-b06e-3c46a142d720"
      },
      "outputs": [],
      "source": [
        "print(X_train2.isna().sum())\n",
        "print(X_train2.isna().any().any())\n",
        "print(X_train2[X_train2.isna().any(axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_with_missing2 = X_train2.columns[X_train2.isna().any()].tolist()\n",
        "cols_with_missing2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DNN\n",
        "\n",
        "We implemented DNN and use \"RandomizedSearchCV\" and \"GridSearchCV\" for fine tuning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing RandomizedSearchCV method for DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "\n",
        "def create_dnn_model(hidden_layers=1, neurons=128, dropout_rate=0.5, l2_lambda=0.01, use_batchnorm=False, activation=\"relu\", optimizer =\"adam\"):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(neurons, activation=activation, input_dim=X_train1.shape[1], kernel_regularizer=l2(l2_lambda)))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Dropout(dropout_rate))\n",
        "    for i in range(hidden_layers):\n",
        "        dnn_model.add(Dense(neurons, activation=activation, kernel_regularizer=l2(l2_lambda)))\n",
        "        if use_batchnorm:\n",
        "            dnn_model.add(BatchNormalization())\n",
        "        dnn_model.add(Dropout(dropout_rate))\n",
        "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
        "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "\n",
        "# Define the hyperparameters for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    \"hidden_layers\": range(1, 6),\n",
        "    \"neurons\": range(5, 30),\n",
        "    \"dropout_rate\":[0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    \"l2_lambda\": [0.01, 0.1, 1],\n",
        "    \"use_batchnorm\": [False, True],\n",
        "    \"activation\": [\"relu\", \"tanh\"],\n",
        "    \"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"]\n",
        "}\n",
        "\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1_score': make_scorer(f1_score)}\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.0001\n",
        "    for i in range(1, 2):\n",
        "        if epoch >= 250 * i:\n",
        "            lr /= 2\n",
        "    print(f'Learning rate at epoch {epoch}: {lr}')\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "dnn_model = KerasClassifier(build_fn=create_dnn_model, verbose=1, epochs=500)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=dnn_model, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring=scoring, refit='accuracy')\n",
        "random_result = random_search.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "best_model = random_result.best_estimator_.model\n",
        "history = best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "results_df = pd.DataFrame(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "best_model = create_dnn_model(**random_search.best_params_)\n",
        "best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256,\n",
        "                         shuffle=True)\n",
        "\n",
        "print(f\"Best parameters: {random_search.best_params_}\")\n",
        "print(f\"Best score: {random_search.best_score_}\")\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "with open('rnd_best_parameters.txt', 'w') as f:\n",
        "    f.write(str(random_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "\n",
        "def create_dnn_model(hidden_layers=1, neurons=128, dropout_rate=0.5, l2_lambda=0.01, use_batchnorm=False, activation=\"relu\", optimizer =\"adam\"):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(neurons, activation=activation, input_dim=X_train1.shape[1], kernel_regularizer=l2(l2_lambda)))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Dropout(dropout_rate))\n",
        "    for i in range(hidden_layers):\n",
        "        dnn_model.add(Dense(neurons, activation=activation, kernel_regularizer=l2(l2_lambda)))\n",
        "        if use_batchnorm:\n",
        "            dnn_model.add(BatchNormalization())\n",
        "        dnn_model.add(Dropout(dropout_rate))\n",
        "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
        "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "\n",
        "# Define the hyperparameters for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    \"hidden_layers\": range(1, 6),\n",
        "    \"neurons\": range(5, 30),\n",
        "    \"dropout_rate\":[0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    \"l2_lambda\": [0.01, 0.1, 1],\n",
        "    \"use_batchnorm\": [False, True],\n",
        "    \"activation\": [\"relu\", \"tanh\"],\n",
        "    \"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"]\n",
        "}\n",
        "\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision': make_scorer(precision_score),\n",
        "           'recall': make_scorer(recall_score),\n",
        "           'f1_score': make_scorer(f1_score)}\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.0001\n",
        "    for i in range(1, 2):\n",
        "        if epoch >= 250 * i:\n",
        "            lr /= 2\n",
        "    print(f'Learning rate at epoch {epoch}: {lr}')\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "dnn_model = KerasClassifier(build_fn=create_dnn_model, verbose=1, epochs=500)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=dnn_model, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring=scoring, refit='accuracy')\n",
        "random_result = random_search.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "best_model = random_result.best_estimator_.model\n",
        "history = best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "results_df = pd.DataFrame(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "best_model = create_dnn_model(**random_search.best_params_)\n",
        "best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256,\n",
        "                         shuffle=True)\n",
        "\n",
        "print(f\"Best parameters: {random_search.best_params_}\")\n",
        "print(f\"Best score: {random_search.best_score_}\")\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(random_search.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "with open('rnd_best_parameters.txt', 'w') as f:\n",
        "    f.write(str(random_search.best_params_))\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_DNN_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(Y_test1, y_pred_DNN_binary_rnd))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(Y_test1, y_pred_DNN_binary_rnd)\n",
        "print(cm)\n",
        "\n",
        "# Save predictions and true labels to CSV files\n",
        "pd.DataFrame({'y_pred': y_pred_DNN_binary_rnd.ravel()}).to_csv('ypred_DNN_rnd.csv', index=False)\n",
        "pd.DataFrame({'Y_test': Y_test1}).to_csv('Y_test.csv', index=False)\n",
        "\n",
        "# Plot train and validation loss values\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot train and validation accuracy values\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(train_acc, label='Train Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementing GridSearchCV method for DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def create_model(hidden_layers=1, neurons=8, dropout_rate=0.1, l2_lambda=0.01, use_batchnorm=False, activation='relu', optimizer='adam'):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(neurons, activation=activation, input_dim=X_train1.shape[1], kernel_initializer='glorot_uniform', kernel_regularizer=l2(l2_lambda)))\n",
        "    if use_batchnorm:\n",
        "        dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Dropout(dropout_rate))\n",
        "    for i in range(hidden_layers):\n",
        "        dnn_model.add(Dense(neurons, kernel_initializer='glorot_uniform', kernel_regularizer=l2(l2_lambda)))\n",
        "        if use_batchnorm:\n",
        "            dnn_model.add(BatchNormalization())\n",
        "        dnn_model.add(Dropout(dropout_rate))\n",
        "    dnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    dnn_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return dnn_model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=128, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "param_grid = {\n",
        "    \"hidden_layers\": [1, 2, 3, 4],\n",
        "    \"neurons\": [8, 16, 32],\n",
        "    \"dropout_rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "    \"l2_lambda\": [0.01, 0.1],\n",
        "    \"use_batchnorm\": [False, True],\n",
        "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
        "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
        "}\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lr = 0.0001\n",
        "    for i in range(1, 2):\n",
        "        if epoch >= 250 * i:\n",
        "            lr /= 2\n",
        "    print(f'Learning rate at epoch {epoch}: {lr}')\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "dnn_model = KerasClassifier(build_fn=create_dnn_model, verbose=1, epochs=500)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, \n",
        "                       batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "best_model = grid_result.best_estimator_.model\n",
        "history = best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300,\n",
        "                          batch_size=256, shuffle=True, callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "results_df = pd.DataFrame(grid.cv_results_)\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "\n",
        "best_model = create_dnn_model(**grid.best_params_)\n",
        "best_model.fit(X_train1, Y_train1, validation_data=(X_val1, Y_val1), epochs=300, batch_size=256,\n",
        "                         shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"Best parameters: {grid.best_params_}\")\n",
        "print(f\"Best score: {grid.best_score_}\")\n",
        "\n",
        "# Save results in CSV file\n",
        "results_df = pd.DataFrame.from_dict(grid.cv_results_)\n",
        "results_df.to_csv('grid_search_results.csv', index=False)\n",
        "\n",
        "# Save best parameters in txt file\n",
        "with open('grid_best_parameters.txt', 'w') as f:\n",
        "    f.write(str(grid.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_DNN_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(Y_test1, y_pred_DNN_binary_grid))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(Y_test1, y_pred_DNN_binary_grid)\n",
        "print(cm)\n",
        "\n",
        "# Save predictions and true labels to CSV files\n",
        "pd.DataFrame({'y_pred': y_pred_DNN_binary_grid.ravel()}).to_csv('ypred_DNN_grid.csv', index=False)\n",
        "#pd.DataFrame({'Y_test': Y_test}).to_csv('Y_test.csv', index=False)\n",
        "\n",
        "# Plot train and validation loss values\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot train and validation accuracy values\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(train_acc, label='Train Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip install xgboost\n",
        "#pip install scipy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GridSearchCV for XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [10, 20],\n",
        "    'learning_rate': [0.001, 0.05],\n",
        "    'n_estimators': [ 1000,2000,5000],\n",
        "    'min_child_weight': [ 20,10],\n",
        "    'subsample': [0.5,0.8],\n",
        "    'colsample_bytree': [1.0, 0.8,0.1],\n",
        "    'gamma': [ 0.2,0.5],\n",
        "    'reg_alpha': [ 0.1,0.5],\n",
        "    'reg_lambda': [ 2,5],\n",
        "}\n",
        "\n",
        "grid_search_XGB = GridSearchCV(estimator=xgb_model, param_grid=param_grid, n_jobs=-1, verbose=1,cv=2)\n",
        "grid_search_XGB.fit(X_train1, Y_train1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Best hyperparameters: \", grid_search_XGB.best_params_)\n",
        "print(\"Best score: \", grid_search_XGB.best_score_)\n",
        "\n",
        "best_model = grid_search_XGB.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test1)\n",
        "\n",
        "\n",
        "# Convert y_pred from probabilities to binary predictions\n",
        "y_pred_XGB_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_XGB_binary_grid))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_XGB_binary_grid))\n",
        "\n",
        "# Save the XGB predictions to a CSV file\n",
        "y_pred = pd.DataFrame(y_pred_XGB_binary_grid)\n",
        "y_pred.to_csv('y_pred_XGB_binary_grid.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RandomizedSearchCV for XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define the model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Define hyperparameters and their values for tuning\n",
        "param_dist = {\n",
        "    'max_depth': randint(1, 30),\n",
        "    'learning_rate': uniform(0.001, 0.1),\n",
        "    'n_estimators': randint(6998, 7000),\n",
        "    'min_child_weight': randint(1, 30),\n",
        "    'subsample': uniform(0.1, 0.9),\n",
        "    'colsample_bytree': uniform(0.1, 0.9),\n",
        "    'gamma': uniform(0, 1),\n",
        "    'reg_alpha': uniform(0, 1),\n",
        "    'reg_lambda': uniform(1, 10),\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV to find the best hyperparameters\n",
        "random_search_XGB = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_jobs=-1, verbose=2, n_iter=100, cv=5)\n",
        "random_search_XGB.fit(X_train1, Y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Best hyperparameters: \", random_search_XGB.best_params_)\n",
        "print(\"Best score: \", random_search_XGB.best_score_)\n",
        "\n",
        "best_model = random_search_XGB.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test1)\n",
        "\n",
        "\n",
        "# Convert y_pred from probabilities to binary predictions\n",
        "y_pred_XGB_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_XGB_binary_rnd))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_XGB_binary_rnd))\n",
        "\n",
        "# Save the XGB predictions to a CSV file\n",
        "y_pred = pd.DataFrame(y_pred_XGB_binary_rnd)\n",
        "y_pred.to_csv('y_pred_XGB_binary_rnd.csv', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ranndom Forest, RF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RandomizedSearchCV for RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "param_distributions = {\n",
        "    'n_estimators': range(100, 3000),\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "random_search_RF = RandomizedSearchCV(rf, param_distributions=param_distributions, n_iter=100, cv=5)\n",
        "random_search_RF.fit(X_train1, Y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters: \", random_search_RF.best_params_)\n",
        "print(\"Best score: \", random_search_RF.best_score_)\n",
        "\n",
        "best_model = random_search_RF.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_RF_binary_rnd = (y_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_RF_binary_rnd))\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_RF_binary_rnd))\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred_RF_binary_rnd)\n",
        "y_pred.to_csv('y_pred_RF_binary_rnd.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GridSearchCV for RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [500100, 1000, 2000],\n",
        "    'max_depth': [5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [2, 4,6],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "grid_search_RF = GridSearchCV(rf, param_grid=param_grid, cv=2)\n",
        "grid_search_RF.fit(X_train1, Y_train1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters: \", grid_search_RF.best_params_)\n",
        "print(\"Best score: \", grid_search_RF.best_score_)\n",
        "\n",
        "best_model = grid_search_RF.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test1)\n",
        "y_pred_RF_binary_grid = (y_pred > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(Y_test1, y_pred_RF_binary_grid))\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(Y_test1, y_pred_RF_binary_grid))\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred_RF_binary_grid)\n",
        "y_pred.to_csv('y_pred_RF_binary_grid.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_DNNg= y_pred_DNN_binary_grid\n",
        "Y_pred_DNNr= y_pred_DNN_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_XGBg= y_pred_XGB_binary_grid\n",
        "Y_pred_XGBr= y_pred_XGB_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_pred_RFg= y_pred_RF_binary_grid\n",
        "Y_pred_RFr= y_pred_RF_binary_rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "preds = np.hstack([Y_pred_DNNr.to_numpy().reshape(-1, 1), Y_pred_XGBr.to_numpy().reshape(-1, 1), Y_pred_RFr.to_numpy().reshape(-1, 1)])\n",
        "ensemble_preds = mode(preds, axis=1)[0]\n",
        "ensemble_preds = ensemble_preds.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "ensemble_preds = np.array(ensemble_preds)\n",
        "cm = confusion_matrix(Y_test1, ensemble_preds)\n",
        "report = classification_report(Y_test1, ensemble_preds)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "preds = np.hstack([Y_pred_DNNr.to_numpy().reshape(-1, 1), Y_pred_XGBr.to_numpy().reshape(-1, 1), Y_pred_RFr.to_numpy().reshape(-1, 1)])\n",
        "ensemble_preds = mode(preds, axis=1)[0]\n",
        "ensemble_preds = ensemble_preds.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "ensemble_preds = np.array(ensemble_preds)\n",
        "cm = confusion_matrix(Y_test1, ensemble_preds)\n",
        "report = classification_report(Y_test1, ensemble_preds)\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
